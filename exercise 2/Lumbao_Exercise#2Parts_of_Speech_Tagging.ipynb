{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4c6fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\Monaliza\n",
      "[nltk_data]     Lumbao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\Monaliza\n",
      "[nltk_data]     Lumbao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('brown',quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ed89ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Thirty-three', 'NUM')], [('Scotty', 'NOUN'), ('did', 'VERB'), ('not', 'ADV'), ('go', 'VERB'), ('back', 'ADV'), ('to', 'ADP'), ('school', 'NOUN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = nltk.corpus.brown.sents(categories='fiction')\n",
    "DATA_TAGGED = nltk.corpus.brown.tagged_sents(categories='fiction',tagset='universal')\n",
    "\n",
    "DATA_TAGGED[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6f18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(len(DATA_TAGGED) * 0.75)\n",
    "DATA_TRAIN = DATA_TAGGED[:train_split]\n",
    "DATA_TEST = DATA_TAGGED[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0615c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4249, 4249, 3186, 1063)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DATA), len(DATA_TAGGED), len(DATA_TRAIN), len(DATA_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af49ec6",
   "metadata": {},
   "source": [
    "## 1. Explore the performance of N-Gram taggers on the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e8b06",
   "metadata": {},
   "source": [
    "### a. Unigram Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5f8b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8438119069961422"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger = nltk.tag.UnigramTagger(DATA_TRAIN)\n",
    "unigram_tagger.evaluate(DATA_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8f8514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Thirty-three', 'NUM')],\n",
       " [('Scotty', 'NOUN'),\n",
       "  ('did', 'VERB'),\n",
       "  ('not', 'ADV'),\n",
       "  ('go', 'VERB'),\n",
       "  ('back', 'ADV'),\n",
       "  ('to', 'PRT'),\n",
       "  ('school', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('His', 'DET'),\n",
       "  ('parents', 'NOUN'),\n",
       "  ('talked', 'VERB'),\n",
       "  ('seriously', 'ADV'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('lengthily', 'ADV'),\n",
       "  ('to', 'PRT'),\n",
       "  ('their', 'DET'),\n",
       "  ('own', 'ADJ'),\n",
       "  ('doctor', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('to', 'PRT'),\n",
       "  ('a', 'DET'),\n",
       "  ('specialist', 'NOUN'),\n",
       "  ('at', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('University', 'NOUN'),\n",
       "  ('Hospital', 'NOUN'),\n",
       "  ('--', '.'),\n",
       "  ('Mr.', 'NOUN'),\n",
       "  ('McKinley', 'NOUN'),\n",
       "  ('was', 'VERB'),\n",
       "  ('entitled', 'VERB'),\n",
       "  ('to', 'PRT'),\n",
       "  ('a', 'DET'),\n",
       "  ('discount', 'NOUN'),\n",
       "  ('for', 'ADP'),\n",
       "  ('members', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('his', 'DET'),\n",
       "  ('family', 'NOUN'),\n",
       "  ('--', '.'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('it', 'PRON'),\n",
       "  ('was', 'VERB'),\n",
       "  ('decided', 'VERB'),\n",
       "  ('it', 'PRON'),\n",
       "  ('would', 'VERB'),\n",
       "  ('be', 'VERB'),\n",
       "  ('best', 'ADJ'),\n",
       "  ('for', 'ADP'),\n",
       "  ('him', 'PRON'),\n",
       "  ('to', 'PRT'),\n",
       "  ('take', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('remainder', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('term', 'NOUN'),\n",
       "  ('off', 'PRT'),\n",
       "  (',', '.'),\n",
       "  ('spend', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('lot', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('time', 'NOUN'),\n",
       "  ('in', 'ADP'),\n",
       "  ('bed', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  (',', '.'),\n",
       "  ('for', 'ADP'),\n",
       "  ('the', 'DET'),\n",
       "  ('rest', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('do', 'VERB'),\n",
       "  ('pretty', 'ADV'),\n",
       "  ('much', 'ADJ'),\n",
       "  ('as', 'ADP'),\n",
       "  ('he', 'PRON'),\n",
       "  ('chose', 'VERB'),\n",
       "  ('--', '.'),\n",
       "  ('provided', 'VERB'),\n",
       "  (',', '.'),\n",
       "  ('of', 'ADP'),\n",
       "  ('course', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('he', 'PRON'),\n",
       "  ('chose', 'VERB'),\n",
       "  ('to', 'PRT'),\n",
       "  ('do', 'VERB'),\n",
       "  ('nothing', 'NOUN'),\n",
       "  ('too', 'ADV'),\n",
       "  ('exciting', 'ADJ'),\n",
       "  ('or', 'CONJ'),\n",
       "  ('too', 'ADV'),\n",
       "  ('debilitating', 'ADJ'),\n",
       "  ('.', '.')],\n",
       " [('His', 'DET'),\n",
       "  ('teacher', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('his', 'DET'),\n",
       "  ('school', 'NOUN'),\n",
       "  ('principal', 'NOUN'),\n",
       "  ('were', 'VERB'),\n",
       "  ('conferred', 'VERB'),\n",
       "  ('with', 'ADP'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('everyone', 'NOUN'),\n",
       "  ('agreed', 'VERB'),\n",
       "  ('that', 'ADP'),\n",
       "  (',', '.'),\n",
       "  ('if', 'ADP'),\n",
       "  ('he', 'PRON'),\n",
       "  ('kept', 'VERB'),\n",
       "  ('up', 'PRT'),\n",
       "  ('with', 'ADP'),\n",
       "  ('a', 'DET'),\n",
       "  ('certain', 'ADJ'),\n",
       "  ('amount', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('work', 'NOUN'),\n",
       "  ('at', 'ADP'),\n",
       "  ('home', 'NOUN'),\n",
       "  (',', '.'),\n",
       "  ('there', 'ADV'),\n",
       "  ('was', 'VERB'),\n",
       "  ('little', 'ADJ'),\n",
       "  ('danger', 'NOUN'),\n",
       "  ('of', 'ADP'),\n",
       "  ('his', 'DET'),\n",
       "  ('losing', 'VERB'),\n",
       "  ('a', 'DET'),\n",
       "  ('term', 'NOUN'),\n",
       "  ('.', '.')],\n",
       " [('Scotty', 'NOUN'),\n",
       "  ('accepted', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('decision', 'NOUN'),\n",
       "  ('with', 'ADP'),\n",
       "  ('indifference', 'NOUN'),\n",
       "  ('and', 'CONJ'),\n",
       "  ('did', 'VERB'),\n",
       "  ('not', 'ADV'),\n",
       "  ('enter', 'VERB'),\n",
       "  ('the', 'DET'),\n",
       "  ('arguments', 'NOUN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.tag_sents(DATA)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fed39c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9633715977771468\n"
     ]
    }
   ],
   "source": [
    "unigran_tagger_train_accuracy = unigram_tagger.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", unigran_tagger_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead90538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.8438119069961422\n"
     ]
    }
   ],
   "source": [
    "unigram_tagger_test_accuracy = unigram_tagger.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", unigram_tagger_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5965b",
   "metadata": {},
   "source": [
    "### b. Unigram Tagger with a verb backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdfaf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tagger = nltk.tag.DefaultTagger('VERB')\n",
    "unigram_tagger_backoff = nltk.tag.UnigramTagger(DATA_TRAIN, backoff=default_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f680e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9633715977771468\n"
     ]
    }
   ],
   "source": [
    "unigram_tagger_backoff_train_accuracy = unigram_tagger_backoff.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", unigram_tagger_backoff_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fdfa632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.8678448545511417\n"
     ]
    }
   ],
   "source": [
    "unigram_tagger_backoff_test_accuracy = unigram_tagger_backoff.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", unigram_tagger_backoff_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab632ad",
   "metadata": {},
   "source": [
    "### c. Trigram Tagger with Unigram Tagger and adjective backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73237a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_tagger = nltk.tag.DefaultTagger('ADJ')\n",
    "adjective_tagger_backoff = nltk.tag.UnigramTagger(DATA_TRAIN, backoff=adjective_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96a45be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tagger_backoff = nltk.tag.TrigramTagger(DATA_TRAIN, backoff=adjective_tagger_backoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c0c0e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9799618707662353\n"
     ]
    }
   ],
   "source": [
    "trigram_tag_train = trigram_tagger_backoff.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", trigram_tag_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62c46991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.8609112709832134\n"
     ]
    }
   ],
   "source": [
    "trigram_tag_test = trigram_tagger_backoff.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", trigram_tag_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a61fd47",
   "metadata": {},
   "source": [
    "### d. Trigram Tagger with a Bigram Tagger backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50959abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tagger_backoff = nltk.tag.BigramTagger(DATA_TRAIN, backoff=unigram_tagger_backoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d5487f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tribigram_tagger_backoff = nltk.tag.TrigramTagger(DATA_TRAIN, backoff=bigram_tagger_backoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0df72cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9796982111710543\n"
     ]
    }
   ],
   "source": [
    "tribigram_tag_train = tribigram_tagger_backoff.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", tribigram_tag_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "642fefde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.8716505056824106\n"
     ]
    }
   ],
   "source": [
    "tribigram_tag_test = tribigram_tagger_backoff.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", tribigram_tag_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d669b6",
   "metadata": {},
   "source": [
    "## 2. Train an Average Perceptron Tagger with different iterations. Compare the results of using different iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a903f",
   "metadata": {},
   "source": [
    "### a. 1 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4caf896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_trained_1 = nltk.perceptron.PerceptronTagger(load=False)\n",
    "perceptron_trained_1.train(DATA_TRAIN, nr_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5007843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9591327627469274\n"
     ]
    }
   ],
   "source": [
    "pt_iter_1_train = perceptron_trained_1.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", pt_iter_1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6099b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9283182149932229\n"
     ]
    }
   ],
   "source": [
    "pt_iter_1_test = perceptron_trained_1.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", pt_iter_1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ae05d",
   "metadata": {},
   "source": [
    "### b. 5 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d36ca1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_trained_5 = nltk.perceptron.PerceptronTagger(load=False)\n",
    "perceptron_trained_5.train(DATA_TRAIN, nr_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8363619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9947470896036994\n"
     ]
    }
   ],
   "source": [
    "pt_iter_5_train = perceptron_trained_5.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", pt_iter_5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d49e72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9500052132207277\n"
     ]
    }
   ],
   "source": [
    "pt_iter_5_test = perceptron_trained_5.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", pt_iter_5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63c81c",
   "metadata": {},
   "source": [
    "### c. 10 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d7881d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_trained_10 = nltk.perceptron.PerceptronTagger(load=False)\n",
    "perceptron_trained_10.train(DATA_TRAIN, nr_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac8ba137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9989250801119539\n"
     ]
    }
   ],
   "source": [
    "pt_iter_10_train = perceptron_trained_10.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", pt_iter_10_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e8689e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9517255760608904\n"
     ]
    }
   ],
   "source": [
    "pt_iter_10_test = perceptron_trained_10.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", pt_iter_10_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4834013",
   "metadata": {},
   "source": [
    "## 3. Train a 3 Conditional Random Field using a different custom feature function. The feature function must contain the features below. Model A should use features a-c. Model B should use features a-e and Model C should use all the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdd7ef",
   "metadata": {},
   "source": [
    "### Model A (Features a-c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abdd6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelA_features(sentence, index):\n",
    "    return {\n",
    "        # a. Previous, Current, and Next Word\n",
    "        # Current word\n",
    "        'word': sentence[index],\n",
    "        # Previous word\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        # Next word\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        \n",
    "        # b. 1-3 Character Prefix\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        \n",
    "        # c. 1-3 Character Suffix\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "599e660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_custom_A = nltk.crf.CRFTagger(feature_func=modelA_features)\n",
    "crf_custom_A.train(DATA_TRAIN, 'crf_custom_A.tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fd6e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9786232912830082\n"
     ]
    }
   ],
   "source": [
    "crf_modelA_train = crf_custom_A.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", crf_modelA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "280ae304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9516213116463351\n"
     ]
    }
   ],
   "source": [
    "crf_modelA_test = crf_custom_A.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", crf_modelA_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86aceb",
   "metadata": {},
   "source": [
    "### Model B (Features a-e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6098cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelB_features(sentence, index):\n",
    "    return {\n",
    "        # a. Previous, Current, and Next Word\n",
    "        # Current word\n",
    "        'word': sentence[index],\n",
    "        # Previous word\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        # Next word\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        \n",
    "        # b. 1-3 Character Prefix\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        \n",
    "        # c. 1-3 Character Suffix\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        \n",
    "        # d. Capitalize\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        \n",
    "        # e. Word contains a number\n",
    "        'is_numeric': sentence[index].isdigit()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e2ddca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_custom_B = nltk.crf.CRFTagger(feature_func=modelB_features)\n",
    "crf_custom_B.train(DATA_TRAIN, 'crf_custom_B.tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3f62d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9785827282683649\n"
     ]
    }
   ],
   "source": [
    "crf_modelB_train = crf_custom_B.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", crf_modelB_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2966493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9516734438536127\n"
     ]
    }
   ],
   "source": [
    "crf_modelB_test = crf_custom_B.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", crf_modelB_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1cdfed",
   "metadata": {},
   "source": [
    "### Model C (All features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9dce4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelC_features(sentence, index):\n",
    "    return {\n",
    "        # a. Previous, Current, and Next Word\n",
    "        # Current word\n",
    "        'word': sentence[index],\n",
    "        # Previous word\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        # Next word\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        \n",
    "        # b. 1-3 Character Prefix\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        \n",
    "        # c. 1-3 Character Suffix\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        \n",
    "        # d. Capitalize\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        \n",
    "        # e. Word contains a number\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        \n",
    "        # f. Word is first in the sentence\n",
    "        'is_first': index == 0,\n",
    "        \n",
    "        # g. Word is last in the sentence\n",
    "        'is_last': index == len(sentence) - 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a515057",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_custom_C = nltk.crf.CRFTagger(feature_func=modelC_features)\n",
    "crf_custom_C.train(DATA_TRAIN, 'crf_custom_C.tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d873a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  0.9785421652537216\n"
     ]
    }
   ],
   "source": [
    "crf_modelC_train = crf_custom_C.evaluate(DATA_TRAIN)\n",
    "print(\"Training data accuracy: \", crf_modelC_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e3ef970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  0.9516734438536127\n"
     ]
    }
   ],
   "source": [
    "crf_modelC_test = crf_custom_C.evaluate(DATA_TEST)\n",
    "print(\"Testing data accuracy: \", crf_modelC_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647a420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
